{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074fc639",
   "metadata": {},
   "source": [
    "#### exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f31cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef502a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv to dataframe\n",
    "pl_ames = pl.read_csv(\"../AmesHousing.csv\")\n",
    "pl_xlsx = pl.read_excel(\"../Neighborhood_names.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13137771",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_ames.join(\n",
    "    pl_xlsx,\n",
    "    left_on=\"Neighborhood\",\n",
    "    right_on=\"Neighborhood\",\n",
    "    how=\"left\",\n",
    ").write_csv(\"ames_neighborhoods.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6b1da",
   "metadata": {},
   "source": [
    "#### exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into subsets by type\n",
    "pl_ames_int = pl_ames.select(pl.col(pl.Int64))\n",
    "pl_ames_string = pl_ames.select(pl.col(pl.String))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fa33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all distinct types\n",
    "print(set(pl_ames.dtypes))\n",
    "\n",
    "# count number of each type\n",
    "number_int = pl_ames.dtypes.count(pl.Int64)\n",
    "number_string = pl_ames.dtypes.count(pl.String)\n",
    "\n",
    "print(f\"Number of int columns: {number_int}, Number of string columns: {number_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all columns with missing values, and show how many\n",
    "pl_ames.null_count().transpose(include_header=True).filter(pl.col(\"column_0\") > 0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61617ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is sales price complete\n",
    "pl_ames[\"SalePrice\"].is_null().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c803c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ames = pd.read_csv(\"../AmesHousing.csv\")\n",
    "pd_xlsx = pd.read_excel(\"../Neighborhood_names.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ames.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct summary statistics\n",
    "pl_ames_int.mean()\n",
    "pl_ames_int.median()\n",
    "pl_ames_int.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def summary_statistics(df):\n",
    "    for col in df.columns:\n",
    "        print(f\"Summary statistics for {col}:\")\n",
    "        print(f\"Mean: {df[col].n_unique()}\\n\")\n",
    "        print(f\"Median: {df[col].mode()[0]}\\n\")\n",
    "        print(f\"Frequency: {Counter(df[col])}\\n\")\n",
    "\n",
    "summary_statistics(pl_ames_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee132b57",
   "metadata": {},
   "source": [
    "#### exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fcd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reaplce NA with other in string columns\n",
    "pl_ames_string = pl_ames_string.with_columns([\n",
    "    pl.col(col).str.replace(\"NA\", \"other\") for col in pl_ames_string.columns\n",
    "])\n",
    "\n",
    "pl_ames_int_filled = pl_ames_int.fill_null(strategy=\"mean\")\n",
    "pl_ames_string_filled = pl_ames_string.fill_null(\"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_ames_recombined = pl.concat([pl_ames_int_filled, pl_ames_string_filled], how=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast all columns to string\n",
    "\"\"\" pl_ames_int_dc = pl_ames_int_filled.with_columns([\n",
    "    pl.col(col).cast(pl.Int32) for col in pl_ames_int_filled.columns\n",
    "]) \"\"\"\n",
    "\n",
    "def f_pl_downcast_numerical_column(df, s_col):\n",
    "\n",
    "    # Assign Polars series to object ps_col.\n",
    "    ps_col = df[s_col]\n",
    "\n",
    "    # If the data type is Integer.\n",
    "    if ps_col.dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64]:\n",
    "\n",
    "        # Determine min and max value.\n",
    "        n_min = ps_col.min()\n",
    "        n_max = ps_col.max()\n",
    "        \n",
    "        # If all values in ps_col are positive.\n",
    "        if n_min >= 0:\n",
    "            if n_max <= 255:\n",
    "                return pl.col(s_col).cast(pl.UInt8)\n",
    "            elif n_max <= 65535:\n",
    "                return pl.col(s_col).cast(pl.UInt16)\n",
    "            elif n_max <= 4294967295:\n",
    "                return pl.col(s_col).cast(pl.UInt32)\n",
    "            else:\n",
    "                return pl.col(s_col).cast(pl.UInt64)\n",
    "            \n",
    "        # If one or more values are negative. \n",
    "        else:\n",
    "            if n_min >= -128 and n_max <= 127:\n",
    "                return pl.col(s_col).cast(pl.Int8)\n",
    "            elif n_min >= -32768 and n_max <= 32767:\n",
    "                return pl.col(s_col).cast(pl.Int16)\n",
    "            elif n_min >= -2147483648 and n_max <= 2147483647:\n",
    "                return pl.col(s_col).cast(pl.Int32)\n",
    "            else:\n",
    "                return pl.col(s_col).cast(pl.Int64)\n",
    "            \n",
    "    # If the data type is Float64. Note, Polars accepts\n",
    "    # Float32 and Float64.\n",
    "    elif ps_col.dtype == pl.Float64:\n",
    "        return pl.col(s_col).cast(pl.Float32)\n",
    "    \n",
    "    # In all other cases.\n",
    "    else:\n",
    "        return pl.col(s_col)\n",
    "    \n",
    "# Apply the downcasting\n",
    "pl_ames_int_dc = pl_ames_int_filled.with_columns([\n",
    "\n",
    "    # Calling the function above on each column in df_pl_reduced.\n",
    "    f_pl_downcast_numerical_column(pl_ames_int_filled, s_col).alias(s_col)\n",
    "\n",
    "    # Looping through all columns.\n",
    "    # Why can we leave in the categorical columns?\n",
    "    for s_col in pl_ames_int_filled.columns\n",
    "])\n",
    "\n",
    "pl_ames_str_dc = pl_ames_string_filled.with_columns([\n",
    "    pl.col(col).cast(pl.Categorical) for col in pl_ames_string_filled.columns\n",
    "])\n",
    "\n",
    "pl_ames_recombined_dc = pl.concat([pl_ames_int_dc, pl_ames_str_dc], how=\"horizontal\")\n",
    "\n",
    "# size comparison\n",
    "for i in [\n",
    "        pl_ames, pl_ames_recombined, pl_ames_recombined_dc,\n",
    "        pl_ames_int, pl_ames_int_filled, pl_ames_int_dc,\n",
    "        pl_ames_string, pl_ames_string_filled, pl_ames_str_dc\n",
    "    ]:\n",
    "    print( i.estimated_size() )\n",
    "\n",
    "print(f\"Downcast size is only {round(pl_ames_recombined_dc.estimated_size()/pl_ames.estimated_size(), 2)} times the size of the original.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e5c8e",
   "metadata": {},
   "source": [
    "#### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe12d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "pl_ames[\"SalePrice\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75813fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "import altair as alt\n",
    "# plot histogram of SalePrice\n",
    "alt.Chart(pl_ames.to_pandas()).mark_bar().encode(\n",
    "    alt.X(\"SalePrice\", bin=alt.Bin(maxbins=50)),\n",
    "    alt.Y(\"count()\"),\n",
    "    tooltip=[\"SalePrice\", \"count()\"]\n",
    ").properties(\n",
    "    title=\"Histogram of Sale Prices\"\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff39e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n",
    "# scatter plot of SalePrice vs GrLivArea\n",
    "alt.Chart(pl_ames.to_pandas()).mark_circle(size=60).encode(\n",
    "    x='Gr Liv Area',\n",
    "    y='SalePrice',\n",
    "    tooltip=['Gr Liv Area', 'SalePrice']\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ea740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d\n",
    "# box plot of SalePrice by Neighborhood\n",
    "alt.Chart(pl_ames.to_pandas()).mark_boxplot().encode(\n",
    "    x='Neighborhood',\n",
    "    y='SalePrice',\n",
    "    tooltip=['Neighborhood', 'SalePrice']\n",
    ").properties(\n",
    "    title=\"Box Plot of Sale Prices by Neighborhood\"\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e\n",
    "\"\"\" \n",
    "most home prices live between 100k and 200k, with a few outliers above 500k.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab59cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\n",
    "\"\"\" \n",
    "assessing the boxplot of SalePrice by Neighborhood \n",
    "\n",
    "some neighborhoods have a wider range of SalePrices, indicating more variability in home prices.\n",
    "other neighborhoods have a narrower range, suggesting more consistent home prices, but also show more outliers.\n",
    "\n",
    "since some neighbourhoods have a widers spread of SalePrices, the model might not perform well across these neighborhoods.\n",
    "training on these neightbourhoods can lead to overfitting.\n",
    "\n",
    "removing outliers might help improve the model's performance, but means we get a narrower view of the data.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a559c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# scatter plot of salerice vs 5 columns\n",
    "columns_to_plot = [\"Gr Liv Area\", \"Total Bsmt SF\", \"Garage Area\", \"Lot Area\", \"Year Built\"]\n",
    "for col in columns_to_plot:\n",
    "    sns.scatterplot(data=pl_ames.to_pandas(), x=col, y=\"SalePrice\")\n",
    "    sns.regplot(data=pl_ames.to_pandas(), x=col, y=\"SalePrice\", scatter=False, color='red')\n",
    "    plt.title(f'SalePrice vs {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('SalePrice')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1134bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h\n",
    "# pearson correlation matrix for numerical columns\n",
    "correlation_matrix = pl_ames_int.corr()\n",
    "# convert to pandas for better visualization\n",
    "correlation_matrix_pd = correlation_matrix.to_pandas()\n",
    "# show table\n",
    "print(correlation_matrix_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c669d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i\n",
    "# correlation matrix heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix_pd, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix Heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce230b9",
   "metadata": {},
   "source": [
    "#### Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d606de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a \n",
    "# linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# prepare data\n",
    "X = pl_ames_int_filled.drop(\"SalePrice\").to_pandas()\n",
    "y = pl_ames_int_filled[\"SalePrice\"].to_pandas()\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "# create linear regression model\n",
    "model = LinearRegression()\n",
    "# fit model\n",
    "model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate model\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "mse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06131c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b \n",
    "# lasso regression model\n",
    "from sklearn.linear_model import Lasso\n",
    "# create lasso regression model\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "# fit model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "y_lasso_pred = lasso_model.predict(X_test)\n",
    "# evaluate model\n",
    "lasso_mse = root_mean_squared_error(y_test, y_lasso_pred, squared=False)\n",
    "lasso_r2 = r2_score(y_test, y_lasso_pred)\n",
    "print(f'Lasso Mean Squared Error: {lasso_mse}')\n",
    "print(f'Lasso R^2 Score: {lasso_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n",
    "# knn regression model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "# create knn regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "# fit model\n",
    "knn_model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "y_knn_pred = knn_model.predict(X_test)\n",
    "# evaluate model using root mean squared error\n",
    "knn_mse = root_mean_squared_error(y_test, y_knn_pred)\n",
    "knn_rmsle = root_mean_squared_log_error(y_test, y_knn_pred)\n",
    "knn_r2 = r2_score(y_test, y_knn_pred)\n",
    "print(f'KNN Mean Squared Error: {knn_mse}')\n",
    "print(f'KNN R^2 Score: {knn_r2}')\n",
    "# 6\n",
    "print(f'KNN Root Mean Squared Log Error: {knn_rmsle}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
